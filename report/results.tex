\label{sec:results}

The test matrix we use is defined as :
\[
A_{ij} =
\begin{cases}
i, i =j \\
0.5, i = j+1, j-1 \\
0.5, (i, j) \in \{(1, n), (n,1)\} \\
0, otherwise
\end{cases}
\]
\[
B_{ij} = 
\begin{cases}
4, i = j \\
-1, i = j+1, j-1 \\
0, otherwize
\end{cases}
\]
The convergence criteria is either the relative residual $\frac{||Ax-\lambda B x||_2}{||x||_2} < \epsilon$ or the absolute residual $||Ax-\lambda B x||_2 < \epsilon$. When $\lambda$ is very close to zero, the absolute residual works, and when $\lambda$ is not close to zero, the relative residual works. We choose $\epsilon = 10^{-4}$ in our implementation. For the matrices $A$ and $B$ with size $10000 \times 10000$. There are $39$ eigenvalues in $[0, 10]$ : [0.158 0.454 0.726 0.988 1.244 1.497 1.749 1.999 2.250 2.500 2.750 3.000 3.250 3.500 3.750 4.000 4.250 4.500 4.750 5.000 5.250 5.500 5.750 6.000 6.250 6.500 6.750 7.000 7.250 7.500 7.750 8.000 8.250 8.500 8.750 9.000 9.250 9.500 9.750]. One can see they are almost evenly distributed with gap $\sim 0.25$. The residual norms for those eigenvalues in the evaluation are : [$2.38*10^{-5}$, $2.03*10^{-5}$, $2.16*10{-5}$, $2.41*10^{-5}$, $2.69*10^{-5}$, $2.43*10^{-5}$, $2.81*10^{-5}$, 
$2.71*10^{-5}$, $2.72*10^{-5}$, $2.71*10^{-5}$, $2.69*10^{-5}$, $2.79*10^{-5}$, $2.85*10^{-5}$, $2.81*10^{-5}$, 
$2.81*10^{-5}$, $2.79*10^{-5}$, $2.88*10^{-5}$, $3.00*10^{-5}$, $3.03*10^{-5}$, $3.13*10^{-5}$, $3.11*10^{-5}$, 
$3.14*10^{-5}$, $3.34*10^{-5}$, $3.91*10^{-5}$, $4.13*10^{-5}$, $5.11*10^{-5}$, $4.99*10^{-5}$, $6.35*10^{-5}$, 
$8.10*10{-5}$, $1.12*10^{-4}$, $1.26*10^{-4}$, $1.69*10^{-4}$, $2.03*10^{-4}$, $2.48*10^{-4}$, $2.99*10^{-4}$, 
$3.69*10^{-4}$, $4.50*10^{-4}$, $5.43*10^{-4}$, $6.44*10^{-4}$]


\subsection{TraceMin}
For simple TraceMin algorithm, the result on the generated matrices $A$ and $B$ are in Table~\ref{tab:result-tracemin}. In the test we compute the smallest $20$ eigenvalues. The linear solver (CG or MinRes) takes the majority of the runtime (more than $90\%$ percent of the overall runtime). And also with more number of threads, the overall runtime do get decreased, and the major contribution comes from the linear equation solver. The speedup also gets better with larger matrices. 
\begin{table*}
\begin{center}
\begin{tabular}{| c | c | r | r | r | r | r |  r | r | r | r | r |}
\hline
$n = $ & $\#threads$ & \multicolumn{5}{|c|}{ CG} & \multicolumn{5}{|c|}{ MinRes} \\ 
\hline
& & Iter & \multicolumn{4}{|c|} {Time} & Iter & \multicolumn{4}{|c|}{Time} \\
& &       & Total & Jacobi & QR & Linear & & Total & Jacobi & QR & Linear \\
\hline
$10,000$ & 1 &12 & 40.02 & 0.44 & 0.29 & 37.98 &  12 & 16.23 & 0.44 & 0.28 & 14.29\\
$10,000$ & 2 &12 & 29.04 & 1.08 & 0.38 & 26.67 &  12 & 13.80 & 0.97 & 0.34 & 11.68\\
$10,000$ & 4 &12 & 19.54 & 0.94 & 0.42 & 17.50 &  12 & 11.91 & 0.79 & 0.34 & 10.24\\
$10,000$ & 8 &12 & 20.13 & 2.00 & 0.56 & 16.62 &  12 & 11.37 & 0.79& 0.33 & 9.77\\
\hline
$50,000$ & 1 &12 &1188.94 &0.44 &3.26 &1178.90 &  13 & 201.87 & 0.50 & 3.49 & 190.97\\
$50,000$ & 2 &12 &836.09  &0.94 &2.26 &829.11  &  13 & 117.95 & 1.07 & 2.50 & 110.29\\
$50,000$ & 4 &12 &702.03  &0.81 &2.28 &696.19  &  13 & 90.17 & 0.90 & 2.49 & 83.89\\
$50,000$ & 8 &12 &535.96  &0.85 &2.31 &530.09  &  13 & 84.14 & 0.87 & 2.45 & 78.09\\
\hline
$100,000$ & 1 & & & & & &  12 & 622.61 & 0.45 & 8.77 & 600.71\\
$100,000$ & 2 & & & & & &  12 & 406.59 & 0.97 & 6.20 & 391.31\\
$100,000$ & 4 & & & & & &  12 & 250.48 & 0.80 & 6.24 & 238.08\\
$100,000$ & 8 & & & & & &  12 & 236.36 & 0.79 &  6.25 & 224.16\\
\hline
\end{tabular}
\caption{Results on simple TraceMin algorithm.}
\label{tab:result-tracemin}
\end{center}
\end{table*}

\begin{figure}[htbp]
	\centering
	\begin{tikzpicture}
		\begin{axis}[ybar stacked,
				enlargelimits=0.15,
				legend style={at={(0.5,-0.1)},	anchor=north,legend columns=-1},
				symbolic x coords={Basic, Deflation, Davidson},
				xtick=data,
				ylabel={total time (s)},
				thick,
				no markers]
			\addplot table [x=method,y=jacobi] {comparison.dat};
			\addplot table [x=method,y=qr] {comparison.dat};
			\addplot table [x=method,y=linear] {comparison.dat};
			\legend{Jacobi, QR, Linear}
		\end{axis}
	\end{tikzpicture}
	\caption{Time for different variations of TraceMin with serial Jacobi}
  \label{fig:timenodes}
\end{figure}

\subsection{Multisection}
Table~\ref{tab:result-multisection} gives the results on using multisection to compute all eigenvalues in interval $[0, 10]$ (39 eigenvalues in total). In multisection, since we shift the origin of the problem by $(A - \mu B) x = \lambda B x$ in which $\mu$ is the midpoint of each subsection. This will cause the distribution of the eigenvalues to change. So even the number of eigenvalue in each subsection are the same, we may still get different number of iterations on each subproblem. So we only report the time on the subsection which takes the longest time to finish. But we can see that as we divide the entire interval into more subsections, the longest runtime on those subsections are reduced. 

\begin{table*}
\begin{center}
\begin{tabular}{|c | c | c | r | r | r | r | r | r |}
\hline
$\#$proc & Intervals & $\#$eigs & MultiSection & \multicolumn{5}{|c|}{Longest Subsection} \\
  & & &  & Iter & Total & Jacobi & QR & Linear \\
\hline
1 & $[0, 10]$ & 39 & 0 & 29 & 105.36 & 16.82 & 4.76 & 74.90 \\
2 & $[0, 4.28, 10]$ & $[17, 22]$ & 0.76 &  46 & 152.10 & 2.70 & 1.34 & 143.00\\
4 & $[0, 2.67, 5.33, 7.33, 10]$ & $[10, 11, 8, 10]$ & 0.15 & 18 & 49.96 & 0.05 & 0.11 & 49.19 \\
8 &$[0, 1.29, 2.58, 3.87, $ & $[5, 5, 5, 5, 5,$ & &  & & & & \\
& $5.16, 6.45, 7.74, 8.70, 10]$& $5, 4, 5]$& 0.25 & 17 & 29.98 & 0.01 & 0.02 & 29.67\\
\hline
\end{tabular}
\caption{Multisection result on $[0, 10]$ for the $10000 \times 10000$ generated matrix $A$ and $B$.}
\label{tab:result-multisection}
\end{center}
\end{table*}

\begin{figure}[htbp]
	\centering
	\begin{tikzpicture}
		\begin{axis}[xlabel={number of nodes},
				ylabel={total time (s)},
				thick,
				no markers]
			\addplot table [x=nodes,y=time] {multisection_time.dat};
		\end{axis}
	\end{tikzpicture}
	\caption{Total time for different number of nodes used}
  \label{fig:timenodes}
\end{figure}
